{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "model = load_model(\"emotion_model.hdf5\",compile=False)\n",
    "emotion_labels = [\"Angry\",\"Disgust\",\"Fear\",\"Happy\",\"Sad\",\"Surprise\",\"Neutral\"]\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "masks = {\n",
    "    \"Happy\" : cv2.imread(\"./masks/happy.png\",cv2.IMREAD_UNCHANGED),\n",
    "    \"Sad\" : cv2.imread(\"./masks/sad.png\",cv2.IMREAD_UNCHANGED),\n",
    "    \"Angry\" : cv2.imread(\"./masks/angry.png\",cv2.IMREAD_UNCHANGED),\n",
    "    \"Neutral\" : cv2.imread(\"./masks/neutral.png\",cv2.IMREAD_UNCHANGED),\n",
    "}\n",
    "\n",
    "def overlay_mask(face_img,mask_img,x,y,w,h):\n",
    "    mask_resized = cv2.resize(mask_img,(w,h))\n",
    "    mask_rgb = mask_resized[:,:,:3]\n",
    "    mask_alpha = mask_resized[:,:,3]/255.0\n",
    "\n",
    "    for c in range(3):\n",
    "        face_img[y:y+h,x:x+w,c] = ((1.0-mask_alpha)*face_img[y:y+h,x:x+w,c]+mask_alpha*mask_rgb[:,:,c])\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    r,f = cap.read()\n",
    "    if r==False:\n",
    "        break\n",
    "\n",
    "    f = cv2.flip(f,1)\n",
    "    gray = cv2.cvtColor(f,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        face_roi = gray[y:y+h,x:x+w]\n",
    "        face_resized = cv2.resize(face_roi,(64,64))\n",
    "        face_resized = face_resized.astype(\"float\")/255.0\n",
    "        face_resized = img_to_array(face_resized)\n",
    "        face_resized = np.expand_dims(face_resized,axis=-1)\n",
    "        face_resized = np.expand_dims(face_resized,axis=0)\n",
    "\n",
    "        preds = model.predict(face_resized,verbose=0)[0]\n",
    "        emotion = emotion_labels[np.argmax(preds)]\n",
    "\n",
    "        label = f\"{emotion} ({int(np.max(preds)*100)}%)\"\n",
    "        cv2.putText(f,label,(x,y-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,0.9,(255,255,0),2)\n",
    "\n",
    "        if emotion in ['Happy','Sad','Angry','Neutral'] and emotion in masks:\n",
    "            overlay_mask(f,masks[emotion],x,y,w,h)\n",
    "\n",
    "    cv2.imshow(\"Emotion\",f)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xff == ord('d'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef828717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion Detector without mask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "model = load_model(\"emotion_model.hdf5\",compile=False)\n",
    "emotion_labels = [\"Angry\",\"Disgust\",\"Fear\",\"Happy\",\"Sad\",\"Surprise\",\"Neutral\"] \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mp_face = mp.solutions.face_detection\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "face = mp_face.FaceDetection(min_detection_confidence=0.7)\n",
    "\n",
    "while cap.isOpened():\n",
    "    r,f = cap.read()\n",
    "    if r==False:\n",
    "        break\n",
    "    f = cv2.flip(f,1)\n",
    "    rgb = cv2.cvtColor(f,1)\n",
    "    h,w,_ = f.shape\n",
    "\n",
    "    res = face.process(rgb)\n",
    "    \n",
    "    if res.detections:\n",
    "        for detection in res.detections:\n",
    "            bboxc = detection.location_data.relative_bounding_box\n",
    "            x = int(bboxc.xmin*w)\n",
    "            y = int(bboxc.ymin*h)\n",
    "            bw = int(bboxc.width*w)\n",
    "            bh = int(bboxc.height*h)\n",
    "\n",
    "            x,y = max(0,x),max(0,y)\n",
    "\n",
    "            face_roi = f[y:y+bh,x:x+bw]\n",
    "            if face_roi.shape[0]<64 or face_roi.shape[1]<64:\n",
    "                continue\n",
    "\n",
    "            gray_face = cv2.cvtColor(f,cv2.COLOR_BGR2GRAY)\n",
    "            face_resized = cv2.resize(gray_face,(64,64))\n",
    "            face_resized = face_resized.astype(\"float32\")/255.0\n",
    "            face_resized = np.expand_dims(face_resized,axis=-1)\n",
    "            face_resized = np.expand_dims(face_resized,axis=0)\n",
    "\n",
    "            preds = model.predict(face_resized,verbose=0)[0]\n",
    "            emotion_idx = np.argmax(preds)\n",
    "            emotion = emotion_labels[emotion_idx]\n",
    "            confidence = int(np.max(preds)*100)\n",
    "\n",
    "            colors = (0,255,0) if emotion == \"Happy\" else (0,0,255)\n",
    "            cv2.rectangle(f,(x,y),(x+bw,y+bh),colors,2)\n",
    "            label = f\"{emotion} ({confidence}%)\"\n",
    "            cv2.putText(f,label,(x,y-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,colors,2)\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Emotion Detector\",f)\n",
    "    if cv2.waitKey(25) & 0xff == ord('d'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
