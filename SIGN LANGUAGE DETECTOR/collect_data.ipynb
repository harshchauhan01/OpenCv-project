{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe5c93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample 1/30\n",
      "Saved sample 2/30\n",
      "Saved sample 3/30\n",
      "Saved sample 4/30\n",
      "Saved sample 5/30\n",
      "Saved sample 6/30\n",
      "Saved sample 7/30\n",
      "Saved sample 8/30\n",
      "Saved sample 9/30\n",
      "Saved sample 10/30\n",
      "Saved sample 11/30\n",
      "Saved sample 12/30\n",
      "Saved sample 13/30\n",
      "Saved sample 14/30\n",
      "Saved sample 15/30\n",
      "Saved sample 16/30\n",
      "Saved sample 17/30\n",
      "Saved sample 18/30\n",
      "Saved sample 19/30\n",
      "Saved sample 20/30\n",
      "Saved sample 21/30\n",
      "Saved sample 22/30\n",
      "Saved sample 23/30\n",
      "Saved sample 24/30\n",
      "Saved sample 25/30\n",
      "Saved sample 26/30\n",
      "Saved sample 27/30\n",
      "Saved sample 28/30\n",
      "Saved sample 29/30\n",
      "Saved sample 30/30\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "SEQUENCE_LENGTH = 30\n",
    "PHRASE = \"no\"\n",
    "SAMPLES = 30\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7,min_tracking_confidence=0.7)\n",
    "\n",
    "phase_path = os.path.join(DATA_PATH,PHRASE)\n",
    "os.makedirs(phase_path,exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "sequence=[]\n",
    "sample_count=0\n",
    "\n",
    "while cap.isOpened():\n",
    "    r,f = cap.read()\n",
    "    if r==False:\n",
    "        break\n",
    "    f = cv2.flip(f,1)\n",
    "    rgb = cv2.cvtColor(f,1)\n",
    "    res = hands.process(rgb)\n",
    "\n",
    "    if res.multi_hand_landmarks:\n",
    "        for landmarks in res.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(f,landmarks,mp_hands.HAND_CONNECTIONS)\n",
    "        hand = res.multi_hand_landmarks[0]\n",
    "        landmarks = np.array([[lm.x ,lm.y,lm.z] for lm in hand.landmark]).flatten()\n",
    "\n",
    "        if len(sequence)<SEQUENCE_LENGTH:\n",
    "            sequence.append(landmarks)\n",
    "\n",
    "        if len(sequence)==SEQUENCE_LENGTH:\n",
    "            np.save(os.path.join(phase_path,f'{PHRASE}_{sample_count}.npy'),sequence)\n",
    "            print(f'Saved sample {sample_count+1}/{SAMPLES}')\n",
    "            sample_count+=1\n",
    "            sequence=[]\n",
    "    cv2.putText(f,f'Phrase : {PHRASE} | SAMPLES : {sample_count}/{SAMPLES}',(10,30),cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.7,(0,255,0),2)\n",
    "\n",
    "    cv2.imshow(\"Recording...\",f)\n",
    "    key = cv2.waitKey(10)\n",
    "    if  key == ord('d') or sample_count==SAMPLES:\n",
    "        break\n",
    "    elif key==ord('s'):\n",
    "        sequence=[]\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
